{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"LightGBM on GPU with Feature Engineering Optuna and  Visualization.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"cells":[{"cell_type":"markdown","metadata":{"id":"8rvFMzuWXgv1"},"source":["# \"LightGBM on GPU with Feature Engineering, Optuna, and , Visualization\"\r\n","1. Author: [@Satoru Shibata/柴田 怜](https://www.kaggle.com/satorushibata)\r\n","1. The original author: [@tito](https://www.kaggle.com/its7171)\r\n","  - I forked and edited [whose Notebook](https://www.kaggle.com/its7171/lgbm-with-loop-feature-engineering)."]},{"cell_type":"markdown","metadata":{"id":"QQNwsyRnSvk3"},"source":["# Abstract:\r\n","1. [Riiid! Answer Correctness Prediction](https://www.kaggle.com/c/riiid-test-answer-prediction/overview)\r\n","1. This is a Code Competition\r\n","1. So, make the best model here and submit [this Kernel](https://www.kaggle.com/satorushibata/lgbm-with-loop-feature-engineering-optuna-plot)\r\n","1. I thank the original author, [@tito](https://www.kaggle.com/its7171)."]},{"cell_type":"markdown","metadata":{"id":"7LU0pmEiHHAv"},"source":["# Use Google Colaboratory(GPU & 20GB) with Kaggle API:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":189},"id":"DFuLrKTfRw2B","executionInfo":{"status":"error","timestamp":1608419548686,"user_tz":-540,"elapsed":192,"user":{"displayName":"柴田怜","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhkX6yjZ0894Zd8egBkt4WfZMLdPjpzumLqLik2uw=s64","userId":"12005693926568550469"}},"outputId":"47fb670e-971b-4ade-b67b-8314caa1c1cb"},"source":["from google.colab import drive\r\n","drive.mount('/content/drive', force_remount = True)"],"execution_count":1,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[1;32m<ipython-input-1-148b7e1789d7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/drive'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce_remount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"]}]},{"cell_type":"code","metadata":{"id":"UHUwcrBUR0e6","executionInfo":{"status":"ok","timestamp":1608420158634,"user_tz":-540,"elapsed":51,"user":{"displayName":"柴田怜","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhkX6yjZ0894Zd8egBkt4WfZMLdPjpzumLqLik2uw=s64","userId":"12005693926568550469"}}},"source":["import os\r\n","os.chdir('/content/drive/MyDrive')"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"co5yYxUmHzQg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608420162251,"user_tz":-540,"elapsed":2154,"user":{"displayName":"柴田怜","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhkX6yjZ0894Zd8egBkt4WfZMLdPjpzumLqLik2uw=s64","userId":"12005693926568550469"}},"outputId":"fb519add-592e-4ef8-dd66-7d1dfc446925"},"source":["!pip install -q kaggle --upgrade\r\n","!mkdir -p ~/.kaggle\r\n","!cp kaggle.json ~/.kaggle/\r\n","!ls ~/.kaggle\r\n","# I need to set permissions\r\n","!chmod 600 ~/.kaggle/kaggle.json\r\n","# Find the competition name.\r\n","!kaggle competitions list"],"execution_count":7,"outputs":[{"output_type":"stream","text":["コマンドの構文が誤っています。\n","cp: cannot create regular file '~/.kaggle/': No such file or directory\n","ls: cannot access '~/.kaggle': No such file or directory\n","chmod: cannot access '~/.kaggle/kaggle.json': No such file or directory\n","Traceback (most recent call last):\n","  File \"c:\\users\\sator\\anaconda3\\lib\\runpy.py\", line 194, in _run_module_as_main\n","    return _run_code(code, main_globals, None,\n","  File \"c:\\users\\sator\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n","    exec(code, run_globals)\n","  File \"C:\\Users\\sator\\anaconda3\\Scripts\\kaggle.exe\\__main__.py\", line 4, in <module>\n","  File \"c:\\users\\sator\\anaconda3\\lib\\site-packages\\kaggle\\__init__.py\", line 23, in <module>\n","    api.authenticate()\n","  File \"c:\\users\\sator\\anaconda3\\lib\\site-packages\\kaggle\\api\\kaggle_api_extended.py\", line 164, in authenticate\n","    raise IOError('Could not find {}. Make sure it\\'s located in'\n","OSError: Could not find kaggle.json. Make sure it's located in C:\\Users\\sator\\.kaggle. Or use the environment method.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"xqO3-kcQ1Ow6"},"source":["# Maximize the memory of Python3:"]},{"cell_type":"code","metadata":{"id":"ZuvUlUxAJ77G","colab":{"base_uri":"https://localhost:8080/","height":541},"executionInfo":{"status":"error","timestamp":1608420103907,"user_tz":-540,"elapsed":6828,"user":{"displayName":"柴田怜","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhkX6yjZ0894Zd8egBkt4WfZMLdPjpzumLqLik2uw=s64","userId":"12005693926568550469"}},"outputId":"0a503d04-eb40-4292-8563-ad5fd1759989"},"source":["!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\r\n","!pip install gputil\r\n","!pip install psutil\r\n","!pip install humanize\r\n","import psutil\r\n","import humanize\r\n","import os\r\n","import GPUtil as GPU\r\n","GPUs = GPU.getGPUs()\r\n","# XXX: only one GPU on Colab and isn’t guaranteed\r\n","gpu = GPUs[0]\r\n","def printm():\r\n","  process = psutil.Process(os.getpid())\r\n","  print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\r\n","  print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\r\n","printm()"],"execution_count":5,"outputs":[{"output_type":"stream","text":["ln: failed to create symbolic link '/usr/bin/nvidia-smi': No such file or directory\n"],"name":"stderr"},{"output_type":"stream","text":["Collecting gputil\n","  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n","Building wheels for collected packages: gputil\n","  Building wheel for gputil (setup.py): started\n","  Building wheel for gputil (setup.py): finished with status 'done'\n","  Created wheel for gputil: filename=GPUtil-1.4.0-py3-none-any.whl size=7410 sha256=3db9cc710fffdfa96730c916474fbf65297eb573a751e41f765a49efc4471541\n","  Stored in directory: c:\\users\\sator\\appdata\\local\\pip\\cache\\wheels\\ba\\03\\bb\\7a97840eb54479b328672e15a536e49dc60da200fb21564d53\n","Successfully built gputil\n","Installing collected packages: gputil\n","Successfully installed gputil-1.4.0\n","Requirement already satisfied: psutil in c:\\users\\sator\\anaconda3\\lib\\site-packages (5.7.2)\n","Collecting humanize\n","  Downloading humanize-3.2.0-py3-none-any.whl (70 kB)\n","Requirement already satisfied: setuptools in c:\\users\\sator\\anaconda3\\lib\\site-packages (from humanize) (51.0.0.post20201207)\n","Installing collected packages: humanize\n","Successfully installed humanize-3.2.0\n"],"name":"stdout"},{"output_type":"error","ename":"IndexError","evalue":"ignored","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[1;32m<ipython-input-5-92874ec4f84d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mGPUs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGPU\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetGPUs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# XXX: only one GPU on Colab and isn’t guaranteed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mgpu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGPUs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mprintm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m   \u001b[0mprocess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpsutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mIndexError\u001b[0m: list index out of range"]}]},{"cell_type":"markdown","metadata":{"id":"H1C1jYhRKi1u"},"source":["# Preparation for parallel process:\r\n","1. Check the number of CPU cores;\r\n","1. [Reference](https://qiita.com/taka-kawa/items/d1fc1bc0acb3a6ca3031#%E4%B8%A6%E5%88%97%E5%87%A6%E7%90%86%E3%81%A8%E5%8D%98%E7%B4%94%E5%AE%9F%E8%A3%85%E3%81%AE%E5%AE%9F%E8%A1%8C%E6%99%82%E9%96%93%E6%AF%94%E8%BC%83)"]},{"cell_type":"code","metadata":{"id":"VrRCT3obKnCj"},"source":["# Check the number of CPU cores.\r\n","!cat /proc/cpuinfo"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"awovTrXMLxVo"},"source":["!pip install multiprocessing\r\n","from multiprocessing import Pool"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2-JtOUGS8FUd"},"source":["# Prepare the prerequisites:\r\n","## Reference:\r\n","- [Setting LightGBM with GPU on Google Colabratory](https://stackoverflow.com/questions/58707252/get-lightgbm-lgbm-run-with-gpu-on-google-colabratory)\r\n","- [Install LightGBM(BUILD GPU VERSION)](https://pypi.org/project/lightgbm/)"]},{"cell_type":"code","metadata":{"id":"cCJQseBD7YMM"},"source":["!pip install gc\r\n","!pip install sklearn\r\n","!pip install collections\r\n","!pip install tqdm\r\n","!pip install optuna\r\n","!pip install matplotlib\r\n","# To use GPU on LightGBM\r\n","!pip install lightgbm --install-option=--gpu\r\n","!git clone --recursive https://github.com/Microsoft/LightGBM\r\n","!cd LightGBM && rm -rf build && mkdir build && cd build && cmake -DUSE_GPU=1 ../../LightGBM && make -j4 && cd ../python-package && python3 setup.py install --precompile --gpu;"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zXmCDREOsPIm"},"source":["# Prepare to apply GPU to LightGBM:\r\n","## Reference:\r\n","- [GoogleColabratory + GradientBoosting + GPU](https://qiita.com/wakame1367/items/bcf8b760260329fb7136)"]},{"cell_type":"code","metadata":{"id":"32eLEt2rpB8-"},"source":["!git clone --recursive https://github.com/Microsoft/LightGBM\r\n","%cd /content/LightGBM/\r\n","!mkdir build\r\n","!cmake -DUSE_GPU=1 #avoid ..\r\n","!make -j$(nproc)\r\n","!sudo apt-get -y install python-pip\r\n","!sudo -H pip install setuptools pandas numpy scipy scikit-learn -U\r\n","%cd /content/LightGBM/python-package\r\n","!sudo python setup.py install --precompile"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gx76R4aN1gsz"},"source":["# Run the Notebook referring to Kernel of Kaggle:\r\n","1. I created this file based on [this notebook](https://www.kaggle.com/its7171/lgbm-with-loop-feature-engineering);\r\n","1. And I am grateful for [the author, @tito](https://www.kaggle.com/its7171)."]},{"cell_type":"code","metadata":{"id":"OIm_6j6r0R27"},"source":["import pandas as pd\n","import numpy as np\n","import gc\n","from sklearn.metrics import roc_auc_score\n","from collections import defaultdict\n","from tqdm.notebook import tqdm\n","# Automate hyperparameter tuning for LightGBM\n","import optuna\n","import lightgbm as lgb\n","# Plot\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wv2OIYEDs0qN"},"source":["# Make sure this notebook has completed to import LightGBM\r\n","print(lgb.__version__)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vIorOhUZ0R28"},"source":["## Setting:\n","CV files are generated by [this notebook](https://www.kaggle.com/its7171/cv-strategy)"]},{"cell_type":"code","metadata":{"id":"RcWCTPjt0R29"},"source":["train_pickle = 'cv1_train.pickle'\n","valid_pickle = 'cv1_valid.pickle'\n","question_file = 'questions.csv'\n","debug = False        # It were True, I have confirmed that AUC of validation is reduced.\n","validaten_flg = True # It were True, submission.csv could not submit to Kaggle on Kernel."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bek7tUca0R29"},"source":["## Feature Engineering:"]},{"cell_type":"code","metadata":{"id":"gmKTQYFD0R29"},"source":["# funcs for user stats with loop\n","def add_user_feats(df, answered_correctly_sum_u_dict, count_u_dict):\n","    acsu = np.zeros(len(df), dtype=np.int32)\n","    cu = np.zeros(len(df), dtype=np.int32)\n","    for cnt,row in enumerate(tqdm(df[['user_id','answered_correctly']].values)):\n","        acsu[cnt] = answered_correctly_sum_u_dict[row[0]]\n","        cu[cnt] = count_u_dict[row[0]]\n","        answered_correctly_sum_u_dict[row[0]] += row[1]\n","        count_u_dict[row[0]] += 1\n","    user_feats_df = pd.DataFrame({'answered_correctly_sum_u':acsu, 'count_u':cu})\n","    user_feats_df['answered_correctly_avg_u'] = user_feats_df['answered_correctly_sum_u'] / user_feats_df['count_u']\n","    df = pd.concat([df, user_feats_df], axis=1)\n","    return df\n","\n","def add_user_feats_without_update(df, answered_correctly_sum_u_dict, count_u_dict):\n","    acsu = np.zeros(len(df), dtype=np.int32)\n","    cu = np.zeros(len(df), dtype=np.int32)\n","    for cnt,row in enumerate(df[['user_id']].values):\n","        acsu[cnt] = answered_correctly_sum_u_dict[row[0]]\n","        cu[cnt] = count_u_dict[row[0]]\n","    user_feats_df = pd.DataFrame({'answered_correctly_sum_u':acsu, 'count_u':cu})\n","    user_feats_df['answered_correctly_avg_u'] = user_feats_df['answered_correctly_sum_u'] / user_feats_df['count_u']\n","    df = pd.concat([df, user_feats_df], axis=1)\n","    return df\n","\n","def update_user_feats(df, answered_correctly_sum_u_dict, count_u_dict):\n","    for row in df[['user_id','answered_correctly','content_type_id']].values:\n","        if row[2] == 0:\n","            answered_correctly_sum_u_dict[row[0]] += row[1]\n","            count_u_dict[row[0]] += 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tQgPvVYF0R29"},"source":["# read data\n","feld_needed = ['row_id', 'user_id', 'content_id', 'content_type_id', 'answered_correctly', 'prior_question_elapsed_time', 'prior_question_had_explanation']\n","train = pd.read_pickle(train_pickle)[feld_needed]\n","valid = pd.read_pickle(valid_pickle)[feld_needed]\n","if debug:\n","    train = train[:1000000]\n","    valid = valid[:10000]\n","train = train.loc[train.content_type_id == False].reset_index(drop=True)\n","valid = valid.loc[valid.content_type_id == False].reset_index(drop=True)\n","\n","# answered correctly average for each content\n","content_df = train[['content_id','answered_correctly']].groupby(['content_id']).agg(['mean']).reset_index()\n","content_df.columns = ['content_id', 'answered_correctly_avg_c']\n","train = pd.merge(train, content_df, on=['content_id'], how=\"left\")\n","valid = pd.merge(valid, content_df, on=['content_id'], how=\"left\")\n","\n","# user stats features with loops\n","answered_correctly_sum_u_dict = defaultdict(int)\n","count_u_dict = defaultdict(int)\n","train = add_user_feats(train, answered_correctly_sum_u_dict, count_u_dict)\n","valid = add_user_feats(valid, answered_correctly_sum_u_dict, count_u_dict)\n","\n","# fill with mean value for prior_question_elapsed_time\n","# note that `train.prior_question_elapsed_time.mean()` dose not work!\n","# please refer https://www.kaggle.com/its7171/can-we-trust-pandas-mean for detail.\n","prior_question_elapsed_time_mean = train.prior_question_elapsed_time.dropna().values.mean()\n","train['prior_question_elapsed_time_mean'] = train.prior_question_elapsed_time.fillna(prior_question_elapsed_time_mean)\n","valid['prior_question_elapsed_time_mean'] = valid.prior_question_elapsed_time.fillna(prior_question_elapsed_time_mean)\n","\n","# use only last 30M training data for limited memory on kaggle env.\n","#train = train[-30000000:]\n","\n","# part\n","questions_df = pd.read_csv(question_file)\n","train = pd.merge(train, questions_df[['question_id', 'part']], left_on = 'content_id', right_on = 'question_id', how = 'left')\n","valid = pd.merge(valid, questions_df[['question_id', 'part']], left_on = 'content_id', right_on = 'question_id', how = 'left')\n","\n","# changing dtype to avoid lightgbm error\n","train['prior_question_had_explanation'] = train.prior_question_had_explanation.fillna(False).astype('int8')\n","valid['prior_question_had_explanation'] = valid.prior_question_had_explanation.fillna(False).astype('int8')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Zbfkxrs30R2-"},"source":["## Modeling:"]},{"cell_type":"code","metadata":{"id":"M_xsCA4A0R2_"},"source":["TARGET = 'answered_correctly'\n","FEATS = ['answered_correctly_avg_u', 'answered_correctly_sum_u', 'count_u', 'answered_correctly_avg_c', 'part', 'prior_question_had_explanation', 'prior_question_elapsed_time']\n","dro_cols = list(set(train.columns) - set(FEATS))\n","y_tr = train[TARGET]\n","y_va = valid[TARGET]\n","train.drop(dro_cols, axis=1, inplace=True)\n","valid.drop(dro_cols, axis=1, inplace=True)\n","_=gc.collect()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tW0unJoE0R2_"},"source":["lgb_train = lgb.Dataset(train[FEATS], y_tr)\n","lgb_valid = lgb.Dataset(valid[FEATS], y_va, reference = lgb_train)\n","del train, y_tr\n","_=gc.collect()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HkgWF13l0R2_"},"source":["## Tuning with Optuna:\r\n","### Reference:\r\n","- [Optuna/README.md](https://github.com/optuna/optuna/blob/master/README.md)\r\n","- [GPU acceleration for LightGBM](https://www.kaggle.com/vinhnguyen/gpu-acceleration-for-lightgbm/)\r\n","- [verbose_eval](https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.train.html)\r\n","- [Potting on LightGBM](https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.plot_importance.html)\r\n","- [lgb.plot_split_value_histogram](https://www.kaggle.com/madiyar/ieee-fraud-lightgbm-split-value-histogram)\r\n","- [lgb.plot_metric](https://www.kaggle.com/tobikaggle/humble-lightgbm-starter-with-learning-curve)\r\n","- [lgb.plot_tree](https://www.kaggle.com/maria591/lightgbm)\r\n","- [lgb.create_tree_digraph](https://www.programmersought.com/article/794564372/)\r\n","- [roc_auc_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html)\r\n","- [evals_result](https://hk29.hatenablog.jp/entry/2019/12/31/172437)\r\n","- [Debug](https://www.kaggle.com/c/santander-customer-transaction-prediction/discussion/88681)"]},{"cell_type":"code","metadata":{"id":"SqtcCj5DSk5D"},"source":["def objective(trial):\r\n","    params = {\r\n","        'objective': 'binary',\r\n","        'metric': 'AUC',\r\n","        'boosting_type': 'dart', # To improve AUC\r\n","        'lambda_l1': trial.suggest_loguniform('lambda_l1', 0.1, 0.9),\r\n","        'lambda_l2': trial.suggest_loguniform('lambda_l2', 0.1, 0.9),\r\n","        'num_leaves': trial.suggest_int('num_leaves', 2, 256),\r\n","        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4, 1.0),\r\n","        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4, 1.0),\r\n","        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\r\n","        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\r\n","        'device': 'gpu',\r\n","        'gpu_platform_id': 0,\r\n","        'gpu_device_id': 0\r\n","    }\r\n","    # To record evaluation results for plotting\r\n","    evaluation_result = {}\r\n","    # Training\r\n","    gbm = lgb.train(params,\r\n","                    lgb_train,\r\n","                    valid_sets = [lgb_train, lgb_valid],\r\n","                    num_boost_round = int(400),\r\n","                    verbose_eval = int(100),\r\n","                    evals_result = evaluation_result\r\n","                    )\r\n","    # Plots\r\n","    lgb.plot_importance(gbm)\r\n","    plt.show()\r\n","    for feature in FEATS:\r\n","      lgb.plot_split_value_histogram(gbm, feature=feature)\r\n","      plt.show()\r\n","    lgb.plot_metric(evaluation_result, metric='auc')\r\n","    plt.show()\r\n","    lgb.plot_tree(gbm, figsize=(30, 50))\r\n","    plt.show()\r\n","    lgb.create_tree_digraph(gbm, tree_index=int(19), name='Tree digraph')\r\n","    plt.show()\r\n","    # Prediction\r\n","    accuracy = roc_auc_score(y_va, gbm.predict(valid), average='weighted', labels='ROC curve')\r\n","    print('ROC curve:', accuracy)\r\n","    # Output\r\n","    return accuracy"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K_PRvFQld7rt"},"source":["## Run the functions:\r\n","### Reference:\r\n","- [optuna.study](https://optuna.readthedocs.io/en/stable/reference/study.html)\r\n","- [最適なパラメータを効率的に探索しちゃおっちゅうな(Optuna)](https://qiita.com/maskot1977/items/ed698a67b091b5516ab4#lightgbm--optuna)\r\n","- [プロセッサのコアの数を確認する](https://support.microsoft.com/ja-jp/windows/%E3%83%97%E3%83%AD%E3%82%BB%E3%83%83%E3%82%B5%E3%81%AE%E3%82%B3%E3%82%A2%E3%81%AE%E6%95%B0%E3%82%92%E7%A2%BA%E8%AA%8D%E3%81%99%E3%82%8B-3126ef99-0247-33b3-81fc-065e9fb0c35b)"]},{"cell_type":"code","metadata":{"id":"SGfg_38tfjkU"},"source":["with Pool(processes = int(6)) as pool:\r\n","  study = optuna.create_study(direction = 'maximize')\r\n","  study.optimize(objective, n_trials = int(6 // 2), n_jobs = int(6))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FmnZ35_oXqXl"},"source":["## Results of LightGBM at such simulation:"]},{"cell_type":"markdown","metadata":{"id":"PgDKKZJiWWWV"},"source":["### Write .txt about the best of Hyperparameter.\r\n","#### [Reference](https://www.w3schools.com/Python/ref_file_writelines.asp)"]},{"cell_type":"code","metadata":{"id":"ZMzSX-3NWRyA"},"source":["with open('The_best_of_Hyperparameter_on_LightGBM.txt', mode='w') as f:\r\n","    f.writelines(study.best_trial.params)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RHlDxu5sX5_x"},"source":["### Print and confirm."]},{"cell_type":"code","metadata":{"id":"m5jXtxRXobNt"},"source":["print('Number of finished trials:', len(study.trials))\r\n","print('The best of trials:', study.best_trial.params)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uu1CMxNnde3g"},"source":["plt.plot([trial.value for trial in study.trials], label = 'Value')\r\n","plt.grid()\r\n","plt.legend()\r\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LE9i0haHk73l"},"source":["## The best model of LightGBM to train and validate:"]},{"cell_type":"code","metadata":{"id":"5cPPESOps1dB"},"source":["params = {\r\n","        'objective': 'binary',\r\n","        'metric': 'AUC',\r\n","        'boosting_type': 'dart'\r\n","}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q8-YkEejs83o"},"source":["params.update(study.best_trial.params)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OWyvLCpIxqH6"},"source":["print(params)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bw24edLbbJMt"},"source":["### Write .txt about the best of all parameters.\r\n","#### [Reference](https://www.w3schools.com/Python/ref_file_writelines.asp)"]},{"cell_type":"code","metadata":{"id":"zaySP-Z-YidD"},"source":["with open('The_best_of_all_parameters_on_LightGBM.txt', mode='w') as f:\r\n","    f.writelines(paramss)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z08kNeTJk-au"},"source":["model = lgb.train(params,\r\n","                  lgb_train,\r\n","                  valid_sets = [lgb_train, lgb_valid]\r\n","                  # num_boost_round = int(2000),\r\n","                  # verbose_eval = int(100)\r\n","                  )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tWHSit7yN2c9"},"source":["## Write the model.pickle to Kernel notebook of Kaggle:\r\n","### [Reference](https://blog.amedama.jp/entry/2018/05/08/033909)"]},{"cell_type":"code","metadata":{"id":"Z-gEgJLIMFma"},"source":["!pip install pickle\r\n","import pickle"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ste6BCFqJVvp"},"source":["pickle.dump(model, open('The_best_of_model_on_LightGBM.pickle', 'wb'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Zd3bZ-r-0R3A"},"source":["## Inference:"]},{"cell_type":"code","metadata":{"id":"p5rrCSot0R3A"},"source":["class Iter_Valid(object):\n","    def __init__(self, df, max_user=1000):\n","        df = df.reset_index(drop=True)\n","        self.df = df\n","        self.user_answer = df['user_answer'].astype(str).values\n","        self.answered_correctly = df['answered_correctly'].astype(str).values\n","        df['prior_group_responses'] = \"[]\"\n","        df['prior_group_answers_correct'] = \"[]\"\n","        self.sample_df = df[df['content_type_id'] == 0][['row_id']]\n","        self.sample_df['answered_correctly'] = 0\n","        self.len = len(df)\n","        self.user_id = df.user_id.values\n","        self.task_container_id = df.task_container_id.values\n","        self.content_type_id = df.content_type_id.values\n","        self.max_user = max_user\n","        self.current = 0\n","        self.pre_user_answer_list = []\n","        self.pre_answered_correctly_list = []\n","\n","    def __iter__(self):\n","        return self\n","    \n","    def fix_df(self, user_answer_list, answered_correctly_list, pre_start):\n","        df= self.df[pre_start:self.current].copy()\n","        sample_df = self.sample_df[pre_start:self.current].copy()\n","        df.loc[pre_start,'prior_group_responses'] = '[' + \",\".join(self.pre_user_answer_list) + ']'\n","        df.loc[pre_start,'prior_group_answers_correct'] = '[' + \",\".join(self.pre_answered_correctly_list) + ']'\n","        self.pre_user_answer_list = user_answer_list\n","        self.pre_answered_correctly_list = answered_correctly_list\n","        return df, sample_df\n","\n","    def __next__(self):\n","        added_user = set()\n","        pre_start = self.current\n","        pre_added_user = -1\n","        pre_task_container_id = -1\n","        pre_content_type_id = -1\n","        user_answer_list = []\n","        answered_correctly_list = []\n","        while self.current < self.len:\n","            crr_user_id = self.user_id[self.current]\n","            crr_task_container_id = self.task_container_id[self.current]\n","            crr_content_type_id = self.content_type_id[self.current]\n","            if crr_user_id in added_user and (crr_user_id != pre_added_user or (crr_task_container_id != pre_task_container_id and crr_content_type_id == 0 and pre_content_type_id == 0)):\n","                # known user(not prev user or (differnt task container and both question))\n","                return self.fix_df(user_answer_list, answered_correctly_list, pre_start)\n","            if len(added_user) == self.max_user:\n","                if  crr_user_id == pre_added_user and (crr_task_container_id == pre_task_container_id or crr_content_type_id == 1):\n","                    user_answer_list.append(self.user_answer[self.current])\n","                    answered_correctly_list.append(self.answered_correctly[self.current])\n","                    self.current += 1\n","                    continue\n","                else:\n","                    return self.fix_df(user_answer_list, answered_correctly_list, pre_start)\n","            added_user.add(crr_user_id)\n","            pre_added_user = crr_user_id\n","            pre_task_container_id = crr_task_container_id\n","            pre_content_type_id = crr_content_type_id\n","            user_answer_list.append(self.user_answer[self.current])\n","            answered_correctly_list.append(self.answered_correctly[self.current])\n","            self.current += 1\n","        if pre_start < self.current:\n","            return self.fix_df(user_answer_list, answered_correctly_list, pre_start)\n","        else:\n","            raise StopIteration()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4H5fRqviRZ9c"},"source":["# Pointing out by [@tito](https://www.kaggle.com/its7171)\r\n","1. You can debug your inference code to reduce \"Submission Scoring Error\" with `validaten_flg = True`.\r\n","1. Please refer [Time-series API (iter_test) Emulator](https://www.kaggle.com/its7171/time-series-api-iter-test-emulator) about Time-series API (iter_test) Emulator."]},{"cell_type":"code","metadata":{"id":"hxwcBKus0R3B"},"source":["if validaten_flg:\n","    target_df = pd.read_pickle(valid_pickle)\n","    if debug:\n","        target_df = target_df[:10000]\n","    iter_test = Iter_Valid(target_df,max_user=1000)\n","    predicted = []\n","    def set_predict(df):\n","        predicted.append(df)\n","    # reset answered_correctly_sum_u_dict and count_u_dict\n","    answered_correctly_sum_u_dict = defaultdict(int)\n","    count_u_dict = defaultdict(int)\n","    train = pd.read_pickle(train_pickle)[['user_id','answered_correctly','content_type_id']]\n","    if debug:\n","        train = train[:1000000]\n","    train = train[train.content_type_id == False].reset_index(drop=True)\n","    update_user_feats(train, answered_correctly_sum_u_dict, count_u_dict)\n","    del train\n","else:\n","    import riiideducation\n","    env = riiideducation.make_env()\n","    iter_test = env.iter_test()\n","    set_predict = env.predict"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cbhacsrZ0R3B","scrolled":true},"source":["previous_test_df = None\n","for (test_df, sample_prediction_df) in iter_test:\n","    if previous_test_df is not None:\n","        previous_test_df[TARGET] = eval(test_df[\"prior_group_answers_correct\"].iloc[0])\n","        update_user_feats(previous_test_df, answered_correctly_sum_u_dict, count_u_dict)\n","    previous_test_df = test_df.copy()\n","    test_df = test_df[test_df['content_type_id'] == 0].reset_index(drop=True)\n","    test_df = add_user_feats_without_update(test_df, answered_correctly_sum_u_dict, count_u_dict)\n","    test_df = pd.merge(test_df, content_df, on='content_id',  how=\"left\")\n","    test_df = pd.merge(test_df, questions_df, left_on='content_id', right_on='question_id', how='left')\n","    test_df['prior_question_had_explanation'] = test_df.prior_question_had_explanation.fillna(False).astype('int8')\n","    test_df['prior_question_elapsed_time_mean'] = test_df.prior_question_elapsed_time.fillna(prior_question_elapsed_time_mean)\n","    test_df[TARGET] =  model.predict(test_df[FEATS])\n","    set_predict(test_df[['row_id', TARGET]])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_bpHiIdd0R3C"},"source":["if validaten_flg:\n","  y_true = target_df[target_df.content_type_id == 0].answered_correctly\n","  y_pred = pd.concat(predicted).answered_correctly\n","  print(roc_auc_score(y_true, y_pred))\n","  print(roc_curve(y_true, y_pred))\n","  plt.plot(fpr, tpr, color='darkorange',lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n","  plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n","  plt.xlabel('False Positive Rate')\n","  plt.ylabel('True Positive Rate')\n","  plt.title('Receiver operating characteristic example')\n","  plt.legend(loc=\"lower right\")\n","  plt.show()"],"execution_count":null,"outputs":[]}]}