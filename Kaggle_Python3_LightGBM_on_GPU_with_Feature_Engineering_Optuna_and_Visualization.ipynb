{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "LightGBM on GPU with Feature Engineering Optuna and  Visualization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ed4cefab8bca43b0a9e42ed35c78f7bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1fc20ee02085452482b84fc1c670da2b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_cc5e3ebb5fbb4a41a31af268fdc37055",
              "IPY_MODEL_ee3baeeb9c8547d59841a1ff19777a25"
            ]
          }
        },
        "1fc20ee02085452482b84fc1c670da2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cc5e3ebb5fbb4a41a31af268fdc37055": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c2660d1e57b04aa0b7badb4ebfbd1371",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 9559019,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 9559019,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3a2bdd32d4ea44cd85f33bd352a2d3d1"
          }
        },
        "ee3baeeb9c8547d59841a1ff19777a25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_64420e59353942898f9bbba319757d2e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 9559019/9559019 [00:23&lt;00:00, 407717.97it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_542f1b6d47cc438f8e1a805c31d1ffe2"
          }
        },
        "c2660d1e57b04aa0b7badb4ebfbd1371": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3a2bdd32d4ea44cd85f33bd352a2d3d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "64420e59353942898f9bbba319757d2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "542f1b6d47cc438f8e1a805c31d1ffe2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "02955e3113fe4e20bed25e0ff2afb105": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5756b90d055c4ba098082875726ef844",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d00b3936725c48928f55a7455f1ea6bd",
              "IPY_MODEL_9b9d2716338e435bbd626d022bbe5a35"
            ]
          }
        },
        "5756b90d055c4ba098082875726ef844": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d00b3936725c48928f55a7455f1ea6bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ba5aa3cee19d4b92a8544d393382c6fa",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 245585,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 245585,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_13a7c909f07f43818feac303a6868fdd"
          }
        },
        "9b9d2716338e435bbd626d022bbe5a35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2ac97262fd2041e9a2d27dae6fb733a5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 245585/245585 [00:02&lt;00:00, 98474.43it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ddbc97258b68455697db69bb85ec7325"
          }
        },
        "ba5aa3cee19d4b92a8544d393382c6fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "13a7c909f07f43818feac303a6868fdd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2ac97262fd2041e9a2d27dae6fb733a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ddbc97258b68455697db69bb85ec7325": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rvFMzuWXgv1"
      },
      "source": [
        "# \"LightGBM on GPU with Feature Engineering, Optuna, and , Visualization\"\r\n",
        "1. Author: [@Satoru Shibata/柴田 怜](https://www.kaggle.com/satorushibata)\r\n",
        "1. The original author: [@tito](https://www.kaggle.com/its7171)\r\n",
        "  - I forked and edited [whose Notebook](https://www.kaggle.com/its7171/lgbm-with-loop-feature-engineering)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQNwsyRnSvk3"
      },
      "source": [
        "# Abstract:\r\n",
        "1. [Riiid! Answer Correctness Prediction](https://www.kaggle.com/c/riiid-test-answer-prediction/overview)\r\n",
        "1. This is a Code Competition\r\n",
        "1. So, make the best model here and submit [this Kernel](https://www.kaggle.com/satorushibata/lgbm-with-loop-feature-engineering-optuna-plot)\r\n",
        "1. I thank the original author, [@tito](https://www.kaggle.com/its7171)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LU0pmEiHHAv"
      },
      "source": [
        "# Use Google Colaboratory(GPU & 20GB) with Kaggle API:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFuLrKTfRw2B",
        "outputId": "9492c699-1de6-4633-f55b-1fd82a1a7863"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive', force_remount = True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHUwcrBUR0e6"
      },
      "source": [
        "import os\r\n",
        "os.chdir('/content/drive/MyDrive')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "co5yYxUmHzQg",
        "outputId": "51d69692-1be9-4fd7-957e-5f8d5e4e13ca"
      },
      "source": [
        "!pip install -q kaggle --upgrade\r\n",
        "!mkdir -p ~/.kaggle\r\n",
        "!cp kaggle.json ~/.kaggle/\r\n",
        "!ls ~/.kaggle\r\n",
        "# I need to set permissions\r\n",
        "!chmod 600 ~/.kaggle/kaggle.json\r\n",
        "# Find the competition name.\r\n",
        "!kaggle competitions list"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kaggle.json\n",
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.10 / client 1.5.4)\n",
            "ref                                            deadline             category            reward  teamCount  userHasEntered  \n",
            "---------------------------------------------  -------------------  ---------------  ---------  ---------  --------------  \n",
            "contradictory-my-dear-watson                   2030-07-01 23:59:00  Getting Started     Prizes         83            True  \n",
            "gan-getting-started                            2030-07-01 23:59:00  Getting Started     Prizes        177           False  \n",
            "tpu-getting-started                            2030-06-03 23:59:00  Getting Started  Knowledge        265           False  \n",
            "digit-recognizer                               2030-01-01 00:00:00  Getting Started  Knowledge       2130            True  \n",
            "titanic                                        2030-01-01 00:00:00  Getting Started  Knowledge      17080            True  \n",
            "house-prices-advanced-regression-techniques    2030-01-01 00:00:00  Getting Started  Knowledge       4498            True  \n",
            "connectx                                       2030-01-01 00:00:00  Getting Started  Knowledge        370           False  \n",
            "nlp-getting-started                            2030-01-01 00:00:00  Getting Started  Knowledge       1238           False  \n",
            "competitive-data-science-predict-future-sales  2022-12-31 23:59:00  Playground           Kudos       9888           False  \n",
            "ranzcr-clip-catheter-line-classification       2021-03-15 23:59:00  Featured           $50,000        162            True  \n",
            "jane-street-market-prediction                  2021-02-22 23:59:00  Featured          $100,000       1367            True  \n",
            "cassava-leaf-disease-classification            2021-02-18 23:59:00  Research           $18,000       1593            True  \n",
            "rfcx-species-audio-detection                   2021-02-17 23:59:00  Research           $15,000        502            True  \n",
            "acea-water-prediction                          2021-02-17 23:59:00  Analytics          $25,000          0            True  \n",
            "rock-paper-scissors                            2021-02-01 23:59:00  Playground          Prizes       1164            True  \n",
            "hubmap-kidney-segmentation                     2021-02-01 23:59:00  Research           $60,000        558            True  \n",
            "santa-2020                                     2021-02-01 23:59:00  Featured            Prizes        448            True  \n",
            "riiid-test-answer-prediction                   2021-01-07 23:59:00  Featured          $100,000       2870            True  \n",
            "predict-volcanic-eruptions-ingv-oe             2021-01-06 23:59:00  Playground            Swag        488           False  \n",
            "kaggle-survey-2020                             2021-01-06 23:59:00  Analytics          $30,000          0            True  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqO3-kcQ1Ow6"
      },
      "source": [
        "# Maximize the memory of Python3:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZuvUlUxAJ77G",
        "outputId": "5ac1d400-fffc-4d2f-a191-2c4ef1c34b1e"
      },
      "source": [
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\r\n",
        "!pip install gputil\r\n",
        "!pip install psutil\r\n",
        "!pip install humanize\r\n",
        "import psutil\r\n",
        "import humanize\r\n",
        "import os\r\n",
        "import GPUtil as GPU\r\n",
        "GPUs = GPU.getGPUs()\r\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\r\n",
        "gpu = GPUs[0]\r\n",
        "def printm():\r\n",
        "  process = psutil.Process(os.getpid())\r\n",
        "  print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\r\n",
        "  print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\r\n",
        "printm()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gputil in /usr/local/lib/python3.6/dist-packages (1.4.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "Gen RAM Free: 12.7 GB  | Proc size: 112.7 MB\n",
            "GPU RAM Free: 15079MB | Used: 0MB | Util   0% | Total 15079MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1C1jYhRKi1u"
      },
      "source": [
        "# Preparation for parallel process:\r\n",
        "1. Check the number of CPU cores;\r\n",
        "1. [Reference](https://qiita.com/taka-kawa/items/d1fc1bc0acb3a6ca3031#%E4%B8%A6%E5%88%97%E5%87%A6%E7%90%86%E3%81%A8%E5%8D%98%E7%B4%94%E5%AE%9F%E8%A3%85%E3%81%AE%E5%AE%9F%E8%A1%8C%E6%99%82%E9%96%93%E6%AF%94%E8%BC%83)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrRCT3obKnCj",
        "outputId": "9b9af6e2-b784-479f-c7f7-9795ab3ad144"
      },
      "source": [
        "# Check the number of CPU cores.\r\n",
        "!cat /proc/cpuinfo"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processor\t: 0\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 79\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "stepping\t: 0\n",
            "microcode\t: 0x1\n",
            "cpu MHz\t\t: 2200.000\n",
            "cache size\t: 56320 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 2\n",
            "core id\t\t: 0\n",
            "cpu cores\t: 1\n",
            "apicid\t\t: 0\n",
            "initial apicid\t: 0\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 13\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n",
            "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa\n",
            "bogomips\t: 4400.00\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n",
            "processor\t: 1\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 79\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "stepping\t: 0\n",
            "microcode\t: 0x1\n",
            "cpu MHz\t\t: 2200.000\n",
            "cache size\t: 56320 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 2\n",
            "core id\t\t: 0\n",
            "cpu cores\t: 1\n",
            "apicid\t\t: 1\n",
            "initial apicid\t: 1\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 13\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n",
            "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa\n",
            "bogomips\t: 4400.00\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awovTrXMLxVo",
        "outputId": "0e0818ec-4774-422d-9c40-dabe815330b4"
      },
      "source": [
        "!pip install multiprocessing\r\n",
        "from multiprocessing import Pool"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting multiprocessing\n",
            "  Using cached https://files.pythonhosted.org/packages/b8/8a/38187040f36cec8f98968502992dca9b00cc5e88553e01884ba29cbe6aac/multiprocessing-2.6.2.1.tar.gz\n",
            "\u001b[31mERROR: Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-JtOUGS8FUd"
      },
      "source": [
        "# Prepare the prerequisites:\r\n",
        "## Reference:\r\n",
        "- [Setting LightGBM with GPU on Google Colabratory](https://stackoverflow.com/questions/58707252/get-lightgbm-lgbm-run-with-gpu-on-google-colabratory)\r\n",
        "- [Install LightGBM(BUILD GPU VERSION)](https://pypi.org/project/lightgbm/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCJQseBD7YMM",
        "outputId": "87aaa04f-a1b1-4332-f6e5-1fb2af9c6bdd"
      },
      "source": [
        "!pip install gc\r\n",
        "!pip install sklearn\r\n",
        "!pip install collections\r\n",
        "!pip install tqdm\r\n",
        "!pip install optuna\r\n",
        "!pip install matplotlib\r\n",
        "# To use GPU on LightGBM\r\n",
        "!pip install lightgbm --install-option=--gpu\r\n",
        "!git clone --recursive https://github.com/Microsoft/LightGBM\r\n",
        "!cd LightGBM && rm -rf build && mkdir build && cd build && cmake -DUSE_GPU=1 ../../LightGBM && make -j4 && cd ../python-package && python3 setup.py install --precompile --gpu;"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement gc (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for gc\u001b[0m\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.23.2)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.19.4)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.5.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.0.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (2.1.0)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement collections (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for collections\u001b[0m\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.41.1)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.6/dist-packages (2.3.0)\n",
            "Requirement already satisfied: alembic in /usr/local/lib/python3.6/dist-packages (from optuna) (1.4.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.6/dist-packages (from optuna) (20.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from optuna) (1.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from optuna) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from optuna) (1.19.4)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from optuna) (1.3.20)\n",
            "Requirement already satisfied: cliff in /usr/local/lib/python3.6/dist-packages (from optuna) (3.5.0)\n",
            "Requirement already satisfied: cmaes>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from optuna) (0.7.0)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.6/dist-packages (from optuna) (4.6.2)\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.6/dist-packages (from optuna) (1.5.4)\n",
            "Requirement already satisfied: python-editor>=0.3 in /usr/local/lib/python3.6/dist-packages (from alembic->optuna) (1.0.4)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.6/dist-packages (from alembic->optuna) (1.1.3)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from alembic->optuna) (2.8.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging>=20.0->optuna) (2.4.7)\n",
            "Requirement already satisfied: stevedore>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (3.3.0)\n",
            "Requirement already satisfied: PyYAML>=3.12 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (3.13)\n",
            "Requirement already satisfied: PrettyTable<0.8,>=0.7.2 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (0.7.2)\n",
            "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (5.5.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (1.15.0)\n",
            "Requirement already satisfied: cmd2!=0.8.3,>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (1.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from Mako->alembic->optuna) (1.1.1)\n",
            "Requirement already satisfied: importlib-metadata>=1.7.0; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from stevedore>=2.0.1->cliff->optuna) (3.3.0)\n",
            "Requirement already satisfied: colorama>=0.3.7 in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (0.4.4)\n",
            "Requirement already satisfied: pyperclip>=1.6 in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (1.8.1)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (20.3.0)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=1.7.0; python_version < \"3.8\"->stevedore>=2.0.1->cliff->optuna) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=1.7.0; python_version < \"3.8\"->stevedore>=2.0.1->cliff->optuna) (3.7.4.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.19.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n",
            "/usr/local/lib/python3.6/dist-packages/pip/_internal/commands/install.py:283: UserWarning: Disabling all use of wheels due to the use of --build-options / --global-options / --install-options.\n",
            "  cmdoptions.check_install_build_global(options)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.6/dist-packages (3.1.1.99)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.6/dist-packages (from lightgbm) (0.36.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from lightgbm) (1.19.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from lightgbm) (1.5.4)\n",
            "Requirement already satisfied: scikit-learn!=0.22.0 in /usr/local/lib/python3.6/dist-packages (from lightgbm) (0.23.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn!=0.22.0->lightgbm) (2.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn!=0.22.0->lightgbm) (1.0.0)\n",
            "fatal: destination path 'LightGBM' already exists and is not an empty directory.\n",
            "-- The C compiler identification is GNU 7.5.0\n",
            "-- The CXX compiler identification is GNU 7.5.0\n",
            "-- Check for working C compiler: /usr/bin/cc\n",
            "-- Check for working C compiler: /usr/bin/cc -- works\n",
            "-- Detecting C compiler ABI info\n",
            "-- Detecting C compiler ABI info - done\n",
            "-- Detecting C compile features\n",
            "-- Detecting C compile features - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++\n",
            "-- Check for working CXX compiler: /usr/bin/c++ -- works\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "-- Found OpenMP_C: -fopenmp (found version \"4.5\") \n",
            "-- Found OpenMP_CXX: -fopenmp (found version \"4.5\") \n",
            "-- Found OpenMP: TRUE (found version \"4.5\")  \n",
            "-- Looking for CL_VERSION_2_2\n",
            "-- Looking for CL_VERSION_2_2 - found\n",
            "-- Found OpenCL: /usr/lib/x86_64-linux-gnu/libOpenCL.so (found version \"2.2\") \n",
            "-- OpenCL include directory: /usr/include\n",
            "-- Boost version: 1.65.1\n",
            "-- Found the following Boost libraries:\n",
            "--   filesystem\n",
            "--   system\n",
            "-- Performing Test MM_PREFETCH\n",
            "-- Performing Test MM_PREFETCH - Success\n",
            "-- Using _mm_prefetch\n",
            "-- Performing Test MM_MALLOC\n",
            "-- Performing Test MM_MALLOC - Success\n",
            "-- Using _mm_malloc\n",
            "-- Configuring done\n",
            "-- Generating done\n",
            "-- Build files have been written to: /content/drive/My Drive/LightGBM/build\n",
            "\u001b[35m\u001b[1mScanning dependencies of target _lightgbm\u001b[0m\n",
            "\u001b[35m\u001b[1mScanning dependencies of target lightgbm\u001b[0m\n",
            "[  0%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/boosting/boosting.cpp.o\u001b[0m\n",
            "[  0%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/boosting/gbdt.cpp.o\u001b[0m\n",
            "[  1%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/boosting/gbdt_model_text.cpp.o\u001b[0m\n",
            "[  2%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/main.cpp.o\u001b[0m\n",
            "[  4%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/application/application.cpp.o\u001b[0m\n",
            "[  5%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/boosting/gbdt_prediction.cpp.o\u001b[0m\n",
            "[  7%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/boosting/prediction_early_stop.cpp.o\u001b[0m\n",
            "[  8%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/bin.cpp.o\u001b[0m\n",
            "[ 10%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/config.cpp.o\u001b[0m\n",
            "[ 11%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/boosting/boosting.cpp.o\u001b[0m\n",
            "[ 13%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/boosting/gbdt.cpp.o\u001b[0m\n",
            "[ 14%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/config_auto.cpp.o\u001b[0m\n",
            "[ 16%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/boosting/gbdt_model_text.cpp.o\u001b[0m\n",
            "[ 17%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/boosting/gbdt_prediction.cpp.o\u001b[0m\n",
            "[ 19%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/dataset.cpp.o\u001b[0m\n",
            "[ 20%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/boosting/prediction_early_stop.cpp.o\u001b[0m\n",
            "[ 22%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/bin.cpp.o\u001b[0m\n",
            "[ 23%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/config.cpp.o\u001b[0m\n",
            "[ 25%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/dataset_loader.cpp.o\u001b[0m\n",
            "[ 26%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/config_auto.cpp.o\u001b[0m\n",
            "[ 28%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/file_io.cpp.o\u001b[0m\n",
            "[ 29%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/json11.cpp.o\u001b[0m\n",
            "[ 31%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/dataset.cpp.o\u001b[0m\n",
            "[ 32%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/metadata.cpp.o\u001b[0m\n",
            "[ 34%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/parser.cpp.o\u001b[0m\n",
            "[ 35%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/train_share_states.cpp.o\u001b[0m\n",
            "[ 37%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/tree.cpp.o\u001b[0m\n",
            "[ 38%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/metric/dcg_calculator.cpp.o\u001b[0m\n",
            "[ 40%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/dataset_loader.cpp.o\u001b[0m\n",
            "[ 41%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/file_io.cpp.o\u001b[0m\n",
            "[ 43%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/json11.cpp.o\u001b[0m\n",
            "[ 44%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/metric/metric.cpp.o\u001b[0m\n",
            "[ 46%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/metadata.cpp.o\u001b[0m\n",
            "[ 47%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/network/ifaddrs_patch.cpp.o\u001b[0m\n",
            "[ 49%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/network/linker_topo.cpp.o\u001b[0m\n",
            "[ 50%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/network/linkers_mpi.cpp.o\u001b[0m\n",
            "[ 52%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/network/linkers_socket.cpp.o\u001b[0m\n",
            "[ 53%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/network/network.cpp.o\u001b[0m\n",
            "[ 55%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/parser.cpp.o\u001b[0m\n",
            "[ 56%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/objective/objective_function.cpp.o\u001b[0m\n",
            "[ 58%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/treelearner/cuda_tree_learner.cpp.o\u001b[0m\n",
            "[ 59%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/treelearner/data_parallel_tree_learner.cpp.o\u001b[0m\n",
            "[ 61%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/treelearner/feature_parallel_tree_learner.cpp.o\u001b[0m\n",
            "[ 62%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/train_share_states.cpp.o\u001b[0m\n",
            "[ 64%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/tree.cpp.o\u001b[0m\n",
            "[ 65%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/treelearner/gpu_tree_learner.cpp.o\u001b[0m\n",
            "[ 67%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/treelearner/serial_tree_learner.cpp.o\u001b[0m\n",
            "[ 68%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/treelearner/tree_learner.cpp.o\u001b[0m\n",
            "[ 70%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/metric/dcg_calculator.cpp.o\u001b[0m\n",
            "[ 71%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/metric/metric.cpp.o\u001b[0m\n",
            "[ 73%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/treelearner/voting_parallel_tree_learner.cpp.o\u001b[0m\n",
            "[ 74%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/network/ifaddrs_patch.cpp.o\u001b[0m\n",
            "[ 76%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/network/linker_topo.cpp.o\u001b[0m\n",
            "[ 77%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/c_api.cpp.o\u001b[0m\n",
            "[ 79%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/network/linkers_mpi.cpp.o\u001b[0m\n",
            "[ 80%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/network/linkers_socket.cpp.o\u001b[0m\n",
            "[ 82%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/network/network.cpp.o\u001b[0m\n",
            "[ 83%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/objective/objective_function.cpp.o\u001b[0m\n",
            "[ 85%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/treelearner/cuda_tree_learner.cpp.o\u001b[0m\n",
            "[ 86%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/treelearner/data_parallel_tree_learner.cpp.o\u001b[0m\n",
            "[ 88%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/treelearner/feature_parallel_tree_learner.cpp.o\u001b[0m\n",
            "[ 89%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/treelearner/gpu_tree_learner.cpp.o\u001b[0m\n",
            "[ 91%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/treelearner/serial_tree_learner.cpp.o\u001b[0m\n",
            "[ 92%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/treelearner/tree_learner.cpp.o\u001b[0m\n",
            "[ 94%] \u001b[32m\u001b[1mLinking CXX shared library ../lib_lightgbm.so\u001b[0m\n",
            "[ 95%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/treelearner/voting_parallel_tree_learner.cpp.o\u001b[0m\n",
            "[ 95%] Built target _lightgbm\n",
            "[ 97%] \u001b[32m\u001b[1mLinking CXX executable ../lightgbm\u001b[0m\n",
            "[ 97%] Built target lightgbm\n",
            "running install\n",
            "running build\n",
            "running build_py\n",
            "INFO:root:Generating grammar tables from /usr/lib/python3.6/lib2to3/Grammar.txt\n",
            "INFO:root:Generating grammar tables from /usr/lib/python3.6/lib2to3/PatternGrammar.txt\n",
            "running egg_info\n",
            "writing lightgbm.egg-info/PKG-INFO\n",
            "writing dependency_links to lightgbm.egg-info/dependency_links.txt\n",
            "writing requirements to lightgbm.egg-info/requires.txt\n",
            "writing top-level names to lightgbm.egg-info/top_level.txt\n",
            "reading manifest template 'MANIFEST.in'\n",
            "no previously-included directories found matching 'build'\n",
            "warning: no files found matching 'LICENSE'\n",
            "warning: no files found matching '*.txt'\n",
            "warning: no files found matching '*.so' under directory 'lightgbm'\n",
            "warning: no files found matching 'compile/CMakeLists.txt'\n",
            "warning: no files found matching 'compile/CMakeIntegratedOpenCL.cmake'\n",
            "warning: no files found matching '*.so' under directory 'compile'\n",
            "warning: no files found matching '*.dll' under directory 'compile/Release'\n",
            "warning: no files found matching 'compile/compute/CMakeLists.txt'\n",
            "warning: no files found matching '*' under directory 'compile/compute/cmake'\n",
            "warning: no files found matching '*' under directory 'compile/compute/include'\n",
            "warning: no files found matching '*' under directory 'compile/compute/meta'\n",
            "warning: no files found matching 'compile/external_libs/fast_double_parser/CMakeLists.txt'\n",
            "warning: no files found matching 'compile/external_libs/fast_double_parser/LICENSE'\n",
            "warning: no files found matching 'compile/external_libs/fast_double_parser/LICENSE.BSL'\n",
            "warning: no files found matching '*' under directory 'compile/external_libs/fast_double_parser/include'\n",
            "warning: no files found matching 'compile/external_libs/fmt/CMakeLists.txt'\n",
            "warning: no files found matching 'compile/external_libs/fmt/LICENSE.rst'\n",
            "warning: no files found matching '*' under directory 'compile/external_libs/fmt/include'\n",
            "warning: no files found matching '*' under directory 'compile/include'\n",
            "warning: no files found matching '*' under directory 'compile/src'\n",
            "warning: no files found matching 'LightGBM.sln' under directory 'compile/windows'\n",
            "warning: no files found matching 'LightGBM.vcxproj' under directory 'compile/windows'\n",
            "warning: no files found matching '*.dll' under directory 'compile/windows/x64/DLL'\n",
            "warning: no previously-included files matching '*.py[co]' found anywhere in distribution\n",
            "warning: no previously-included files found matching 'compile/compute/.git'\n",
            "writing manifest file 'lightgbm.egg-info/SOURCES.txt'\n",
            "running install_lib\n",
            "INFO:LightGBM:Installing lib_lightgbm from: ['../lib_lightgbm.so']\n",
            "copying ../lib_lightgbm.so -> /usr/local/lib/python3.6/dist-packages/lightgbm\n",
            "running install_egg_info\n",
            "removing '/usr/local/lib/python3.6/dist-packages/lightgbm-3.1.1.99-py3.6.egg-info' (and everything under it)\n",
            "Copying lightgbm.egg-info to /usr/local/lib/python3.6/dist-packages/lightgbm-3.1.1.99-py3.6.egg-info\n",
            "running install_scripts\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXmCDREOsPIm"
      },
      "source": [
        "# Prepare to apply GPU to LightGBM:\r\n",
        "## Reference:\r\n",
        "- [GoogleColabratory + GradientBoosting + GPU](https://qiita.com/wakame1367/items/bcf8b760260329fb7136)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32eLEt2rpB8-",
        "outputId": "463c1b9b-4f00-41f5-e6fe-07a4e9b80596"
      },
      "source": [
        "!git clone --recursive https://github.com/Microsoft/LightGBM\r\n",
        "%cd /content/LightGBM/\r\n",
        "!mkdir build\r\n",
        "!cmake -DUSE_GPU=1 #avoid ..\r\n",
        "!make -j$(nproc)\r\n",
        "!sudo apt-get -y install python-pip\r\n",
        "!sudo -H pip install setuptools pandas numpy scipy scikit-learn -U\r\n",
        "%cd /content/LightGBM/python-package\r\n",
        "!sudo python setup.py install --precompile"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'LightGBM' already exists and is not an empty directory.\n",
            "[Errno 2] No such file or directory: '/content/LightGBM/'\n",
            "/content\n",
            "mkdir: cannot create directory ‘build’: File exists\n",
            "CMake Error: The source directory \"/content/drive/My Drive\" does not appear to contain CMakeLists.txt.\n",
            "Specify --help for usage, or press the help button on the CMake GUI.\n",
            "make: *** No targets specified and no makefile found.  Stop.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "python-pip is already the newest version (9.0.1-2.3~ubuntu1.18.04.4).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 14 not upgraded.\n",
            "Requirement already up-to-date: setuptools in /usr/local/lib/python3.6/dist-packages (51.0.0)\n",
            "Requirement already up-to-date: pandas in /usr/local/lib/python3.6/dist-packages (1.1.5)\n",
            "Requirement already up-to-date: numpy in /usr/local/lib/python3.6/dist-packages (1.19.4)\n",
            "Requirement already up-to-date: scipy in /usr/local/lib/python3.6/dist-packages (1.5.4)\n",
            "Requirement already up-to-date: scikit-learn in /usr/local/lib/python3.6/dist-packages (0.23.2)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (2.1.0)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "[Errno 2] No such file or directory: '/content/LightGBM/python-package'\n",
            "/content\n",
            "python3: can't open file 'setup.py': [Errno 2] No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gx76R4aN1gsz"
      },
      "source": [
        "# Run the Notebook referring to Kernel of Kaggle:\r\n",
        "1. I created this file based on [this notebook](https://www.kaggle.com/its7171/lgbm-with-loop-feature-engineering);\r\n",
        "1. And I am grateful for [the author, @tito](https://www.kaggle.com/its7171)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIm_6j6r0R27"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gc\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from collections import defaultdict\n",
        "from tqdm.notebook import tqdm\n",
        "# Automate hyperparameter tuning for LightGBM\n",
        "import optuna\n",
        "import lightgbm as lgb\n",
        "# Plot\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wv2OIYEDs0qN",
        "outputId": "e32c18cd-53f2-403a-c636-a38bf455c429"
      },
      "source": [
        "# Make sure this notebook has completed to import LightGBM\r\n",
        "print(lgb.__version__)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.1.1.99\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIorOhUZ0R28"
      },
      "source": [
        "## Setting:\n",
        "CV files are generated by [this notebook](https://www.kaggle.com/its7171/cv-strategy)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcWCTPjt0R29"
      },
      "source": [
        "train_pickle = 'cv1_train.pickle'\n",
        "valid_pickle = 'cv1_valid.pickle'\n",
        "question_file = 'questions.csv'\n",
        "debug = False        # It were True, I have confirmed that AUC of validation is reduced.\n",
        "validaten_flg = True # It were True, submission.csv could not submit to Kaggle on Kernel."
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bek7tUca0R29"
      },
      "source": [
        "## Feature Engineering:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmKTQYFD0R29"
      },
      "source": [
        "# funcs for user stats with loop\n",
        "def add_user_feats(df, answered_correctly_sum_u_dict, count_u_dict):\n",
        "    acsu = np.zeros(len(df), dtype=np.int32)\n",
        "    cu = np.zeros(len(df), dtype=np.int32)\n",
        "    for cnt,row in enumerate(tqdm(df[['user_id','answered_correctly']].values)):\n",
        "        acsu[cnt] = answered_correctly_sum_u_dict[row[0]]\n",
        "        cu[cnt] = count_u_dict[row[0]]\n",
        "        answered_correctly_sum_u_dict[row[0]] += row[1]\n",
        "        count_u_dict[row[0]] += 1\n",
        "    user_feats_df = pd.DataFrame({'answered_correctly_sum_u':acsu, 'count_u':cu})\n",
        "    user_feats_df['answered_correctly_avg_u'] = user_feats_df['answered_correctly_sum_u'] / user_feats_df['count_u']\n",
        "    df = pd.concat([df, user_feats_df], axis=1)\n",
        "    return df\n",
        "\n",
        "def add_user_feats_without_update(df, answered_correctly_sum_u_dict, count_u_dict):\n",
        "    acsu = np.zeros(len(df), dtype=np.int32)\n",
        "    cu = np.zeros(len(df), dtype=np.int32)\n",
        "    for cnt,row in enumerate(df[['user_id']].values):\n",
        "        acsu[cnt] = answered_correctly_sum_u_dict[row[0]]\n",
        "        cu[cnt] = count_u_dict[row[0]]\n",
        "    user_feats_df = pd.DataFrame({'answered_correctly_sum_u':acsu, 'count_u':cu})\n",
        "    user_feats_df['answered_correctly_avg_u'] = user_feats_df['answered_correctly_sum_u'] / user_feats_df['count_u']\n",
        "    df = pd.concat([df, user_feats_df], axis=1)\n",
        "    return df\n",
        "\n",
        "def update_user_feats(df, answered_correctly_sum_u_dict, count_u_dict):\n",
        "    for row in df[['user_id','answered_correctly','content_type_id']].values:\n",
        "        if row[2] == 0:\n",
        "            answered_correctly_sum_u_dict[row[0]] += row[1]\n",
        "            count_u_dict[row[0]] += 1"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116,
          "referenced_widgets": [
            "ed4cefab8bca43b0a9e42ed35c78f7bb",
            "1fc20ee02085452482b84fc1c670da2b",
            "cc5e3ebb5fbb4a41a31af268fdc37055",
            "ee3baeeb9c8547d59841a1ff19777a25",
            "c2660d1e57b04aa0b7badb4ebfbd1371",
            "3a2bdd32d4ea44cd85f33bd352a2d3d1",
            "64420e59353942898f9bbba319757d2e",
            "542f1b6d47cc438f8e1a805c31d1ffe2",
            "02955e3113fe4e20bed25e0ff2afb105",
            "5756b90d055c4ba098082875726ef844",
            "d00b3936725c48928f55a7455f1ea6bd",
            "9b9d2716338e435bbd626d022bbe5a35",
            "ba5aa3cee19d4b92a8544d393382c6fa",
            "13a7c909f07f43818feac303a6868fdd",
            "2ac97262fd2041e9a2d27dae6fb733a5",
            "ddbc97258b68455697db69bb85ec7325"
          ]
        },
        "id": "tQgPvVYF0R29",
        "outputId": "ab5651ac-fc7e-4386-d6af-acbc4d386cca"
      },
      "source": [
        "# read data\n",
        "feld_needed = ['row_id', 'user_id', 'content_id', 'content_type_id', 'answered_correctly', 'prior_question_elapsed_time', 'prior_question_had_explanation']\n",
        "train = pd.read_pickle(train_pickle)[feld_needed]\n",
        "valid = pd.read_pickle(valid_pickle)[feld_needed]\n",
        "if debug:\n",
        "    train = train[:1000000]\n",
        "    valid = valid[:10000]\n",
        "train = train.loc[train.content_type_id == False].reset_index(drop=True)\n",
        "valid = valid.loc[valid.content_type_id == False].reset_index(drop=True)\n",
        "\n",
        "# answered correctly average for each content\n",
        "content_df = train[['content_id','answered_correctly']].groupby(['content_id']).agg(['mean']).reset_index()\n",
        "content_df.columns = ['content_id', 'answered_correctly_avg_c']\n",
        "train = pd.merge(train, content_df, on=['content_id'], how=\"left\")\n",
        "valid = pd.merge(valid, content_df, on=['content_id'], how=\"left\")\n",
        "\n",
        "# user stats features with loops\n",
        "answered_correctly_sum_u_dict = defaultdict(int)\n",
        "count_u_dict = defaultdict(int)\n",
        "train = add_user_feats(train, answered_correctly_sum_u_dict, count_u_dict)\n",
        "valid = add_user_feats(valid, answered_correctly_sum_u_dict, count_u_dict)\n",
        "\n",
        "# fill with mean value for prior_question_elapsed_time\n",
        "# note that `train.prior_question_elapsed_time.mean()` dose not work!\n",
        "# please refer https://www.kaggle.com/its7171/can-we-trust-pandas-mean for detail.\n",
        "prior_question_elapsed_time_mean = train.prior_question_elapsed_time.dropna().values.mean()\n",
        "train['prior_question_elapsed_time_mean'] = train.prior_question_elapsed_time.fillna(prior_question_elapsed_time_mean)\n",
        "valid['prior_question_elapsed_time_mean'] = valid.prior_question_elapsed_time.fillna(prior_question_elapsed_time_mean)\n",
        "\n",
        "# use only last 30M training data for limited memory on kaggle env.\n",
        "#train = train[-30000000:]\n",
        "\n",
        "# part\n",
        "questions_df = pd.read_csv(question_file)\n",
        "train = pd.merge(train, questions_df[['question_id', 'part']], left_on = 'content_id', right_on = 'question_id', how = 'left')\n",
        "valid = pd.merge(valid, questions_df[['question_id', 'part']], left_on = 'content_id', right_on = 'question_id', how = 'left')\n",
        "\n",
        "# changing dtype to avoid lightgbm error\n",
        "train['prior_question_had_explanation'] = train.prior_question_had_explanation.fillna(False).astype('int8')\n",
        "valid['prior_question_had_explanation'] = valid.prior_question_had_explanation.fillna(False).astype('int8')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ed4cefab8bca43b0a9e42ed35c78f7bb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=9559019.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "02955e3113fe4e20bed25e0ff2afb105",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=245585.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zbfkxrs30R2-"
      },
      "source": [
        "## Modeling:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_xsCA4A0R2_"
      },
      "source": [
        "TARGET = 'answered_correctly'\n",
        "FEATS = ['answered_correctly_avg_u', 'answered_correctly_sum_u', 'count_u', 'answered_correctly_avg_c', 'part', 'prior_question_had_explanation', 'prior_question_elapsed_time']\n",
        "dro_cols = list(set(train.columns) - set(FEATS))\n",
        "y_tr = train[TARGET]\n",
        "y_va = valid[TARGET]\n",
        "train.drop(dro_cols, axis=1, inplace=True)\n",
        "valid.drop(dro_cols, axis=1, inplace=True)\n",
        "_=gc.collect()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tW0unJoE0R2_"
      },
      "source": [
        "lgb_train = lgb.Dataset(train[FEATS], y_tr)\n",
        "lgb_valid = lgb.Dataset(valid[FEATS], y_va, reference = lgb_train)\n",
        "del train, y_tr\n",
        "_=gc.collect()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkgWF13l0R2_"
      },
      "source": [
        "## Tuning with Optuna:\r\n",
        "### Reference:\r\n",
        "- [Optuna/README.md](https://github.com/optuna/optuna/blob/master/README.md)\r\n",
        "- [GPU acceleration for LightGBM](https://www.kaggle.com/vinhnguyen/gpu-acceleration-for-lightgbm/)\r\n",
        "- [verbose_eval](https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.train.html)\r\n",
        "- [Potting on LightGBM](https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.plot_importance.html)\r\n",
        "- [lgb.plot_split_value_histogram](https://www.kaggle.com/madiyar/ieee-fraud-lightgbm-split-value-histogram)\r\n",
        "- [lgb.plot_metric](https://www.kaggle.com/tobikaggle/humble-lightgbm-starter-with-learning-curve)\r\n",
        "- [lgb.plot_tree](https://www.kaggle.com/maria591/lightgbm)\r\n",
        "- [lgb.create_tree_digraph](https://www.programmersought.com/article/794564372/)\r\n",
        "- [roc_auc_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html)\r\n",
        "- [evals_result](https://hk29.hatenablog.jp/entry/2019/12/31/172437)\r\n",
        "- [Debug](https://www.kaggle.com/c/santander-customer-transaction-prediction/discussion/88681)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqtcCj5DSk5D"
      },
      "source": [
        "def objective(trial):\r\n",
        "    params = {\r\n",
        "        'objective': 'binary',\r\n",
        "        'metric': 'AUC',\r\n",
        "        'boosting_type': 'dart', # To improve AUC\r\n",
        "        'lambda_l1': trial.suggest_loguniform('lambda_l1', 0.1, 0.9),\r\n",
        "        'lambda_l2': trial.suggest_loguniform('lambda_l2', 0.1, 0.9),\r\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 2, 256),\r\n",
        "        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4, 1.0),\r\n",
        "        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4, 1.0),\r\n",
        "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\r\n",
        "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\r\n",
        "        'device': 'gpu',\r\n",
        "        'gpu_platform_id': 0,\r\n",
        "        'gpu_device_id': 0\r\n",
        "    }\r\n",
        "    # To record evaluation results for plotting\r\n",
        "    evaluation_result = {}\r\n",
        "    # Training\r\n",
        "    gbm = lgb.train(params,\r\n",
        "                    lgb_train,\r\n",
        "                    valid_sets = [lgb_train, lgb_valid],\r\n",
        "                    num_boost_round = int(400),\r\n",
        "                    verbose_eval = int(100),\r\n",
        "                    evals_result = evaluation_result\r\n",
        "                    )\r\n",
        "    # Plots\r\n",
        "    lgb.plot_importance(gbm)\r\n",
        "    plt.show()\r\n",
        "    for feature in FEATS:\r\n",
        "      lgb.plot_split_value_histogram(gbm, feature=feature)\r\n",
        "      plt.show()\r\n",
        "    lgb.plot_metric(evaluation_result, metric='auc')\r\n",
        "    plt.show()\r\n",
        "    lgb.plot_tree(gbm, figsize=(30, 50))\r\n",
        "    plt.show()\r\n",
        "    lgb.create_tree_digraph(gbm, tree_index=int(19), name='Tree digraph')\r\n",
        "    plt.show()\r\n",
        "    # Prediction\r\n",
        "    accuracy = roc_auc_score(y_va, gbm.predict(valid), average='weighted', labels='ROC curve')\r\n",
        "    print('ROC curve:', accuracy)\r\n",
        "    # Output\r\n",
        "    return accuracy"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_PRvFQld7rt"
      },
      "source": [
        "## Run the functions:\r\n",
        "### Reference:\r\n",
        "- [optuna.study](https://optuna.readthedocs.io/en/stable/reference/study.html)\r\n",
        "- [最適なパラメータを効率的に探索しちゃおっちゅうな(Optuna)](https://qiita.com/maskot1977/items/ed698a67b091b5516ab4#lightgbm--optuna)\r\n",
        "- [プロセッサのコアの数を確認する](https://support.microsoft.com/ja-jp/windows/%E3%83%97%E3%83%AD%E3%82%BB%E3%83%83%E3%82%B5%E3%81%AE%E3%82%B3%E3%82%A2%E3%81%AE%E6%95%B0%E3%82%92%E7%A2%BA%E8%AA%8D%E3%81%99%E3%82%8B-3126ef99-0247-33b3-81fc-065e9fb0c35b)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGfg_38tfjkU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87e7620e-f9c8-419f-d939-11bebf79d15e"
      },
      "source": [
        "with Pool(processes = int(6)) as pool:\r\n",
        "  study = optuna.create_study(direction = 'maximize')\r\n",
        "  study.optimize(objective, n_trials = int(6 // 2), n_jobs = int(6))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2020-12-19 11:50:45,237]\u001b[0m A new study created in memory with name: no-name-01f3358c-1845-4ddb-bb5e-bb6a9097cd7b\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[100]\ttraining's auc: 0.750413\tvalid_1's auc: 0.760276\n",
            "[100]\ttraining's auc: 0.751167\tvalid_1's auc: 0.761068\n",
            "[100]\ttraining's auc: 0.752196\tvalid_1's auc: 0.761641\n",
            "[200]\ttraining's auc: 0.751079\tvalid_1's auc: 0.761279\n",
            "[200]\ttraining's auc: 0.751801\tvalid_1's auc: 0.761769\n",
            "[200]\ttraining's auc: 0.752762\tvalid_1's auc: 0.762065\n",
            "[300]\ttraining's auc: 0.751794\tvalid_1's auc: 0.761427\n",
            "[300]\ttraining's auc: 0.752534\tvalid_1's auc: 0.761839\n",
            "[300]\ttraining's auc: 0.75333\tvalid_1's auc: 0.762369\n",
            "[400]\ttraining's auc: 0.75207\tvalid_1's auc: 0.761515\n",
            "[400]\ttraining's auc: 0.752854\tvalid_1's auc: 0.761831\n",
            "[400]\ttraining's auc: 0.753709\tvalid_1's auc: 0.762501\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmnZ35_oXqXl"
      },
      "source": [
        "## Results of LightGBM at such simulation:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgDKKZJiWWWV"
      },
      "source": [
        "### Write .txt about the best of Hyperparameter.\r\n",
        "#### [Reference](https://www.w3schools.com/Python/ref_file_writelines.asp)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMzSX-3NWRyA"
      },
      "source": [
        "with open('The_best_of_Hyperparameter_on_LightGBM.txt', mode='w') as f:\r\n",
        "    f.writelines(study.best_trial.params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHlDxu5sX5_x"
      },
      "source": [
        "### Print and confirm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5jXtxRXobNt"
      },
      "source": [
        "print('Number of finished trials:', len(study.trials))\r\n",
        "print('The best of trials:', study.best_trial.params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uu1CMxNnde3g"
      },
      "source": [
        "plt.plot([trial.value for trial in study.trials], label = 'Value')\r\n",
        "plt.grid()\r\n",
        "plt.legend()\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LE9i0haHk73l"
      },
      "source": [
        "## The best model of LightGBM to train and validate:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cPPESOps1dB"
      },
      "source": [
        "params = {\r\n",
        "        'objective': 'binary',\r\n",
        "        'metric': 'AUC',\r\n",
        "        'boosting_type': 'dart'\r\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8-YkEejs83o"
      },
      "source": [
        "params.update(study.best_trial.params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWyvLCpIxqH6"
      },
      "source": [
        "print(params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bw24edLbbJMt"
      },
      "source": [
        "### Write .txt about the best of all parameters.\r\n",
        "#### [Reference](https://www.w3schools.com/Python/ref_file_writelines.asp)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaySP-Z-YidD"
      },
      "source": [
        "with open('The_best_of_all_parameters_on_LightGBM.txt', mode='w') as f:\r\n",
        "    f.writelines(paramss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z08kNeTJk-au"
      },
      "source": [
        "model = lgb.train(params,\r\n",
        "                  lgb_train,\r\n",
        "                  valid_sets = [lgb_train, lgb_valid]\r\n",
        "                  # num_boost_round = int(2000),\r\n",
        "                  # verbose_eval = int(100)\r\n",
        "                  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWHSit7yN2c9"
      },
      "source": [
        "## Write the model.pickle to Kernel notebook of Kaggle:\r\n",
        "### [Reference](https://blog.amedama.jp/entry/2018/05/08/033909)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-gEgJLIMFma"
      },
      "source": [
        "!pip install pickle\r\n",
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ste6BCFqJVvp"
      },
      "source": [
        "pickle.dump(model, open('The_best_of_model_on_LightGBM.pickle', 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zd3bZ-r-0R3A"
      },
      "source": [
        "## Inference:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5rrCSot0R3A"
      },
      "source": [
        "class Iter_Valid(object):\n",
        "    def __init__(self, df, max_user=1000):\n",
        "        df = df.reset_index(drop=True)\n",
        "        self.df = df\n",
        "        self.user_answer = df['user_answer'].astype(str).values\n",
        "        self.answered_correctly = df['answered_correctly'].astype(str).values\n",
        "        df['prior_group_responses'] = \"[]\"\n",
        "        df['prior_group_answers_correct'] = \"[]\"\n",
        "        self.sample_df = df[df['content_type_id'] == 0][['row_id']]\n",
        "        self.sample_df['answered_correctly'] = 0\n",
        "        self.len = len(df)\n",
        "        self.user_id = df.user_id.values\n",
        "        self.task_container_id = df.task_container_id.values\n",
        "        self.content_type_id = df.content_type_id.values\n",
        "        self.max_user = max_user\n",
        "        self.current = 0\n",
        "        self.pre_user_answer_list = []\n",
        "        self.pre_answered_correctly_list = []\n",
        "\n",
        "    def __iter__(self):\n",
        "        return self\n",
        "    \n",
        "    def fix_df(self, user_answer_list, answered_correctly_list, pre_start):\n",
        "        df= self.df[pre_start:self.current].copy()\n",
        "        sample_df = self.sample_df[pre_start:self.current].copy()\n",
        "        df.loc[pre_start,'prior_group_responses'] = '[' + \",\".join(self.pre_user_answer_list) + ']'\n",
        "        df.loc[pre_start,'prior_group_answers_correct'] = '[' + \",\".join(self.pre_answered_correctly_list) + ']'\n",
        "        self.pre_user_answer_list = user_answer_list\n",
        "        self.pre_answered_correctly_list = answered_correctly_list\n",
        "        return df, sample_df\n",
        "\n",
        "    def __next__(self):\n",
        "        added_user = set()\n",
        "        pre_start = self.current\n",
        "        pre_added_user = -1\n",
        "        pre_task_container_id = -1\n",
        "        pre_content_type_id = -1\n",
        "        user_answer_list = []\n",
        "        answered_correctly_list = []\n",
        "        while self.current < self.len:\n",
        "            crr_user_id = self.user_id[self.current]\n",
        "            crr_task_container_id = self.task_container_id[self.current]\n",
        "            crr_content_type_id = self.content_type_id[self.current]\n",
        "            if crr_user_id in added_user and (crr_user_id != pre_added_user or (crr_task_container_id != pre_task_container_id and crr_content_type_id == 0 and pre_content_type_id == 0)):\n",
        "                # known user(not prev user or (differnt task container and both question))\n",
        "                return self.fix_df(user_answer_list, answered_correctly_list, pre_start)\n",
        "            if len(added_user) == self.max_user:\n",
        "                if  crr_user_id == pre_added_user and (crr_task_container_id == pre_task_container_id or crr_content_type_id == 1):\n",
        "                    user_answer_list.append(self.user_answer[self.current])\n",
        "                    answered_correctly_list.append(self.answered_correctly[self.current])\n",
        "                    self.current += 1\n",
        "                    continue\n",
        "                else:\n",
        "                    return self.fix_df(user_answer_list, answered_correctly_list, pre_start)\n",
        "            added_user.add(crr_user_id)\n",
        "            pre_added_user = crr_user_id\n",
        "            pre_task_container_id = crr_task_container_id\n",
        "            pre_content_type_id = crr_content_type_id\n",
        "            user_answer_list.append(self.user_answer[self.current])\n",
        "            answered_correctly_list.append(self.answered_correctly[self.current])\n",
        "            self.current += 1\n",
        "        if pre_start < self.current:\n",
        "            return self.fix_df(user_answer_list, answered_correctly_list, pre_start)\n",
        "        else:\n",
        "            raise StopIteration()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4H5fRqviRZ9c"
      },
      "source": [
        "# Pointing out by [@tito](https://www.kaggle.com/its7171)\r\n",
        "1. You can debug your inference code to reduce \"Submission Scoring Error\" with `validaten_flg = True`.\r\n",
        "1. Please refer [Time-series API (iter_test) Emulator](https://www.kaggle.com/its7171/time-series-api-iter-test-emulator) about Time-series API (iter_test) Emulator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxwcBKus0R3B"
      },
      "source": [
        "if validaten_flg:\n",
        "    target_df = pd.read_pickle(valid_pickle)\n",
        "    if debug:\n",
        "        target_df = target_df[:10000]\n",
        "    iter_test = Iter_Valid(target_df,max_user=1000)\n",
        "    predicted = []\n",
        "    def set_predict(df):\n",
        "        predicted.append(df)\n",
        "    # reset answered_correctly_sum_u_dict and count_u_dict\n",
        "    answered_correctly_sum_u_dict = defaultdict(int)\n",
        "    count_u_dict = defaultdict(int)\n",
        "    train = pd.read_pickle(train_pickle)[['user_id','answered_correctly','content_type_id']]\n",
        "    if debug:\n",
        "        train = train[:1000000]\n",
        "    train = train[train.content_type_id == False].reset_index(drop=True)\n",
        "    update_user_feats(train, answered_correctly_sum_u_dict, count_u_dict)\n",
        "    del train\n",
        "else:\n",
        "    import riiideducation\n",
        "    env = riiideducation.make_env()\n",
        "    iter_test = env.iter_test()\n",
        "    set_predict = env.predict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbhacsrZ0R3B",
        "scrolled": true
      },
      "source": [
        "previous_test_df = None\n",
        "for (test_df, sample_prediction_df) in iter_test:\n",
        "    if previous_test_df is not None:\n",
        "        previous_test_df[TARGET] = eval(test_df[\"prior_group_answers_correct\"].iloc[0])\n",
        "        update_user_feats(previous_test_df, answered_correctly_sum_u_dict, count_u_dict)\n",
        "    previous_test_df = test_df.copy()\n",
        "    test_df = test_df[test_df['content_type_id'] == 0].reset_index(drop=True)\n",
        "    test_df = add_user_feats_without_update(test_df, answered_correctly_sum_u_dict, count_u_dict)\n",
        "    test_df = pd.merge(test_df, content_df, on='content_id',  how=\"left\")\n",
        "    test_df = pd.merge(test_df, questions_df, left_on='content_id', right_on='question_id', how='left')\n",
        "    test_df['prior_question_had_explanation'] = test_df.prior_question_had_explanation.fillna(False).astype('int8')\n",
        "    test_df['prior_question_elapsed_time_mean'] = test_df.prior_question_elapsed_time.fillna(prior_question_elapsed_time_mean)\n",
        "    test_df[TARGET] =  model.predict(test_df[FEATS])\n",
        "    set_predict(test_df[['row_id', TARGET]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bpHiIdd0R3C"
      },
      "source": [
        "if validaten_flg:\n",
        "  y_true = target_df[target_df.content_type_id == 0].answered_correctly\n",
        "  y_pred = pd.concat(predicted).answered_correctly\n",
        "  print(roc_auc_score(y_true, y_pred))\n",
        "  print(roc_curve(y_true, y_pred))\n",
        "  plt.plot(fpr, tpr, color='darkorange',lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "  plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "  plt.xlabel('False Positive Rate')\n",
        "  plt.ylabel('True Positive Rate')\n",
        "  plt.title('Receiver operating characteristic example')\n",
        "  plt.legend(loc=\"lower right\")\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}